---
title: "An Observational Study to COVID-19 and 2020 US Presidential Election: Counties with High Deaths per Case Rate Showed Diminished Support For Trump"
title-block-banner: true
author: "Yiliu Cao"
thanks: "Code and data from this analysis are available at: https://github.com/yiliuc/covid_and_trump_loss.git"
date: "today"
date-format: "long"
abstract: "This study investigate the causal inference between COVID-19 and Donald Trump's loss during the 2020 US Federal Election using the data from MIT Election Data Science Lab and Johns Hopkins University CSSE. The main methodology used in this paper is Propensity Score Matching with with an exploratory analyzing the optimal treatment initially. The key finding suggest that the counties with a death per case rate exceeding the 0.4 quantile threshold shows a reduced voting preference for Trump. Additionally, this paper conducts a counterfactual analysis based on the treatment effect, indicating that Trump might have be secured to re-elect if the disparities in death per case rates were addressed. Future research should aim to refine the propensity score calculations by incorporating additional variables, such as the winning party in each county during the 2016 election."
format: pdf
toc: true
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
library(tidyverse)
library(here)
library(dplyr)
library(knitr)
library(ggplot2)
library(maps)
library(mapdata)
library(RColorBrewer)
library(gridExtra)
library(tools)
library(dplyr)
library(ggplot2)
```

```{r}
#| echo: false
#| message: false

election_data <- read.csv(here("outputs/data/election_data_clean.csv"))
covid_data <- read.csv(here("outputs/data/covid_data_clean.csv"))
acs_data <- read.csv(here("outputs/data/acs_data_clean.csv"))
covid_election_data <- read.csv(here("outputs/data/covid_election.csv"))
data <- read.csv(here("outputs/data/merged_data.csv"))
```

# Introduction
 
At the beginning of 2020, US reported the first COVID-19 cases. This number grows to ten thousand within two months on March 19 and increase dramatically to 100K on March 27 [citation]. At the same year, the U.S. Federal Presidential Election started off and Trump lost to Biden. As of Election Day, there was above 9 million cases and about 0.2 million deaths in US. When people talk about Trump's lost, people always connect it to the pandemic, saying that he "mishandled his greatest test" [citation] and 2016 Election was a historical accident [citation]. However, there is another voice that COVID is not the only or the decisive factor attributing to his lost, his limits as a politican and wasted his advantage on the economy are also important explaining why he lost. This paper will investigate whether the is a causal effect between COVID and Trump's lost. If there is, whether it is strong enough to beath Trump at 2020.

There are existing researches on this. Leaonardo et al. [citation] suggested that Trump could win if there was no COVID but it will be too naive to simply connect his lost to the COVID-19 infection rate. Their research highlighted that the COVID-19 had the most significant negative impacts on those urban areas where there was no stay-at-home orders, especially for those "swing" states. They also argue that the race diversity and education attainment are also important when analysing voting patterns for Trump. In addition to that, Marcus et al. [citation] suggested that the deaths per case is a more crucial indicator than infection rate when analysing the voting for Trump. However, they suggest the voting itself may not capture the impact of COVID as we do not know when did the voters make their decision, especially for early vote. Compared to these researches, Harold [citation] conduct read survey before and after the election to illustrate the impact of COVID pattern, they found that even though COVID has impacts on voting, it is not the dominant factor. Without COVID, Trump was also less likely to re-elect due to US highly polarized political landscape. Similarly, Shang et al. [citation] also conduct a survey and all the participants show natural or negative altitude. They suggest some social activity like "Black lives matter" may have impacts on voting. Furthermore, the 

While all the above researches had investigated the correlation between COVID-19 and votings for Trump. Except conducting real surveys, the methods they used were to conduct a model and find the relevant variables in predicting the (change) vote for Trump. Then conduct counterfactual analysis to predict what will be the voting for Trump if there was no COVID or a certain amount reduce in COVID deaths. Instead using a similar way like those studies, this paper will introduce the method of Propensity Score Matching to find the treatment effect, to see whether those more impacted counties will have different voting patterns for Trump. However, since all counties experienced COVID-19, this paper will firstly find the optimal treatment groups. After that, I will also conduct a counterfactual analysis to see if Trump could re-elect.

There will be five parts in this paper. I will introduce the data used in this paper and present data suammries and visualization in [Data] part. After that, I will introduce the methods in this paper and the corresponding results in  [Methods] and [Results] part, respectively. Then the results will be interpreted and discussed in the [Discussion] part and conclude with limitations and drawbacks in [Conclusion] part..


# Data

## Data sources

The data used in this paper comprised five data sets from three different sources corresponding to different topics. The primary source is MIT Election Data Science Club which build open online data collections of the US Federal or Senate Election results, spanning from nation to county levels. The data extracted is called "County Presidential Election Returns 2000-2020" with about 70,000 rows containing the voting patterns for each candidate and party by county since 2000. Besides that, the data also indicate the types of voting, such as "EARLY VOTE" and "ELECTION DAY," for the same party in the a county. To analyze the voting patterns for Donald J. Trump, I only select the data for 2016 and 2020 US Federal Election for all counties and parties. Thus the filterd data set contains the number of votes through various ways for each county and party.

In addition to that, the study also uses the data regarding COVID-19 from the Center for Systems Science and Engineering (CSSE) at Johns Hopkins University. CSSE collects and reports the local, national, and global multidimensional data, including medicine, health care, disaster response, etc. During the pandemic, they collected the U.S. and international COVID cases and deaths and reported them on their GitHub, summarized by daily reports from April 12, 2020, to March 9, 2023. To access the impact of COVID on 2020 Election, this paper used the daily report on November 3, 2020 which is the election day of 2020 US Federal Election. The resulting data include the aggregates number of cases, deaths and recovers, as well as the incidence rate and case fatility ratio for each county by the election day.

Lastly, this paper also employ the socio-economic data from American Community Survey (ACS). ACS is a online open source database conducted by the U.S. Census Bureau, containing the various soci-economic factors in either geographic levels. The data sets extracted from ACS is 2020 five-year estimates of DP02, DP03 and DP05 which covers the social, economic and demographic characteristics in county level. Since there are thousands of variables, I will only use the variables which are found from my previous paper that are significant in predicting the COVID-19 mortality rate such as the mean household income, high-education attainment etc. The descriptions of all variables can be found on Table 1.

After having five data sets from three sources, they are merged into one big data by counties. Using the merged data, there are some new variables calculated by the exiting variables. In terms of election, I calculate the percentage of vote for each party (candidate) in both 2016 and 2020 Election, and calculate the corresponding change of percentage votes. I also create new variables indicating the winning party in both elections for each county. Additionally, to accurately compare the COVID cases and deaths across all counties, I transform the number of cases and deaths to infection and mortality rate by 10,000 citizens in each county. The final data now consists of 3107 rows with 36 columns. All the important variables are described in Table 1.

```{r}
#| tbl-cap: Descriptions of all important variables in the analyze data
#| label: tbl-descriptions
data.frame(var = c("Income Percentile", "High-Education Attainment",
                   "Private Insurance", "No Insurance", "White Population",
                   "Black Population", "Males Population", "Infection Rate",
                   "Mortality Rate", "Death per Case", "Votes for Democrat (2016)",
                   "Votes for Democrat (2020)", "Votes for Republican (2016)",
                   "Votes for Republican (2020)", "Change of Vote for Republican"),
           code = c("income_pctile", "prop_high_education", "private_insurance",
           "no_insurance", "white_pct", "black_pct", "males", "infrate",
           "mortrate", "dpc", "pct_vote_demo16", "pct_vote_demo", 
           "pct_vote_rep16", "pct_vote_rep", "change_vote_rep"),
           descriptions = c("The income percentile of each county",
                            "The proportion of residents in a county having a at least bachelor degree",
                            "The proportion of local residences having private insurance",
                            "The proportion of local residences without any health insurance",
                            "The proportion of White population",
                            "The proportion of Black population",
                            "The proportion of Males population",
                            "The COVID infection rate, calculated by number of case per 10,000 residences",
                            "The COVID mortality rate, calculated by number of death per 10,000 residences",
                            "The COVID death per 10,000 confirmed cases",
                            "The percentage of votes for the Democrat in 2016",
                            "The percentage of votes for the Democrat in 2020",
                            "The percentage of votes for the Republican in 2016",
                            "The percentage of votes for the Republican in 2020",
                            "The change of vote for the Republican from 2016 to 2020")) %>% 
  rename(`Variables` = var,
         `Coded name` = code,
         `Descriptions` = descriptions) %>% 
  kable(booktabs = TRUE)
```

## Data summaries and visualizations

```{r}
#| echo: false
#| message: false
#| label: tbl-covid
#| tbl-cap: The summary of COVID cases and deaths as of Election Day.
data %>% 
  group_by(winning_party) %>% 
  summarise(n = n(),
            case = mean(cases),
            inf = mean(infrate),
            deaths = mean(deaths),
            mort = mean(mortrate),
            dpc = mean(dpc),
            income = mean(mean_household_income)) %>% 
  rename(`Winning Party` = winning_party,
         `Count` = n,
         `Cases` = case,
         `Infection Rate` = inf,
         `Deaths` = deaths,
         `Mortality Rate` = mort,
         `DPC` = dpc,
         `Income` = income) %>% 
  kable(booktabs = TRUE)
```

@tbl-covid summarize the COVID-19 impacts and income levels between the counties voting for Democrat and Republican. Even though the Republican won about five sixths counties, there is a stark contrast where counties supporting Biden had nearly ten times the average number of COVID-19 cases and deaths compared to those supporting Trump. Despite a similar infection and mortality rates between the two groups, there is still a notable higher death-to-case rate in counties voting for the Republican. Furthermore, these counties also has a lower mean household income than the "Democrat-win" counties. These patterns suggest a potential correlation between the extent of COVID-19 impact and voting behavior in the 2020, where areas more severely affected by COVID-19 were less likely to vote for the Trump, vice-versa. This aligns with mainstream media and intuitive expectations.

```{r}
#| echo: false
#| message: false

get_state_abbreviation <- function(state_names) {
  sapply(state_names, function(state_name) {
    state_data <- state.abb[match(state_name, state.name)]
    if (!is.na(state_data)) {
      return(state_data)
    } else {
      return(NA)  # changed from NULL to NA for consistency in a vector
    }
  })
}

county <- map_data("county")
state <- map_data("state")
county_clean <- county %>% 
  mutate(state = region,
         county = subregion,
         state = get_state_abbreviation(toTitleCase(state)),
         county = toTitleCase(county)) %>% 
  filter(region != "AK" & region != "HI") %>% 
  dplyr::select(-region, -subregion)

merged_data <- county_clean %>% 
  left_join(data, by = c("state", "county"))
```

```{r}
#| echo: false
#| message: false
#| fig.width: 8 
#| fig.height: 8
#| label: fig-map
#| fig-cap: The ratio of votes for the Republican and the infection rate per 100k in each county

p1 <- ggplot(data = merged_data, aes(x = long, y = lat, group = group)) + 
  geom_polygon(aes(fill = pct_vote_rep), color = "black") +
  scale_fill_distiller(palette = "RdBu", direction = -1, na.value = "grey") +
  labs(title = "The relative share of votes between Republican and Democrat party",
       fill = 'Share of Republican') +
  coord_quickmap() +
  theme_void() +
  geom_path(data = state, aes(x = long, y = lat, group = group), color = "black", linewidth = 0.9)

# Second plot
p2 <- ggplot(data = merged_data, aes(x = long, y = lat, group = group)) + 
  geom_polygon(aes(fill = dpc), color = "black") +
  scale_fill_gradient(low = "white", high = "darkblue", na.value = "grey",
                      limits = c(0, 5000), oob = scales::squish) +
  labs(title = "The distribution of death per case rate by 100K",
       fill = 'Death per cases by 100k') +
  coord_quickmap() +
  theme_void() +
  geom_path(data = state, aes(x = long, y = lat, group = group), color = "black", linewidth = 0.9)

# Arrange the plots in a 2x1 layout
grid.arrange(p1, p2, ncol = 1)
```

We can validate our guess from @fig-map which compares the relative ratio of votes for the two parties and the death to cases rate in maps. From the maps, it is clearly more counties had preference for the Republican but the counties with higher death per case rate have a smaller ratio of vote for the Republican and these counties are usually richer ones. The most significant example can be California and New York. In contrast, the states with less impacted by COVID, such as Utah, vote more for Republican.

```{r}
#| fig-cap: The correlation between voting behaviors to income and DPC rate for the Republican and Democrat
#| label: fig-dpc-income

binned_data <- data %>%
  mutate(dpc_pctile = ntile(dpc, 100)) %>%  
  group_by(dpc_pctile) %>%
  summarize(mean_rep = mean(pct_vote_rep, na.rm = TRUE),
            mean_demo = mean(pct_vote_demo, na.rm = TRUE),
            mean_vote_rep = mean(vote_rep, na.rm = TRUE),
            mean_vote_demo = mean(vote_demo, na.rm = TRUE),
            mean_income = mean(mean_household_income))

binned_data2 <- data %>%
  mutate(income_pctile = ntile(mean_household_income, 100)) %>%  
  group_by(income_pctile) %>%
  summarize(mean_rep = mean(pct_vote_rep, na.rm = TRUE),
            mean_demo = mean(pct_vote_demo, na.rm = TRUE),
            mean_vote_rep = mean(vote_rep, na.rm = TRUE),
            mean_vote_demo = mean(vote_demo, na.rm = TRUE)) %>% 
  mutate(sum = mean_rep + mean_demo)

plot1 <- ggplot(binned_data, aes(x = dpc_pctile)) +
  geom_point(aes(y = mean_rep, colour = "Republican"), alpha = 0.25) +  
  geom_smooth(aes(y = mean_rep, colour = "Republican"), 
              method = "lm", formula = y ~ poly(x, 3), se = FALSE) +
  geom_point(aes(y = mean_demo, colour = "Democrat"), alpha = 0.25) + 
  geom_smooth(aes(y = mean_demo, colour = "Democrat"), 
              method = "lm", formula = y ~ poly(x, 3), se = FALSE) +
  geom_vline(xintercept = 25, 
             color = "black", linetype = "dashed", size = 0.6) +
  geom_vline(xintercept = 75, 
             color = "black", linetype = "dashed", size = 0.6) +
  scale_colour_manual(values = c("Republican" = "#FF9999", "Democrat" = "#9999FF"),
                      name = "Party",  
                      labels = c("Democrat", "Republican")) +
  theme_minimal() +
  theme(legend.position = "none") + 
  labs(x = "DPC Rate Percentiles", 
       y = "Votes Share (%)")

plot2 <- ggplot(binned_data, aes(x = dpc_pctile)) +
  geom_point(aes(y = mean_vote_rep, colour = "Republican"), alpha = 0.25) +  
  geom_smooth(aes(y = mean_vote_rep, colour = "Republican"), 
              method = "lm", formula = y ~ poly(x, 3), se = FALSE) +
  geom_point(aes(y = mean_vote_demo, colour = "Democrat"), alpha = 0.25) + 
  geom_smooth(aes(y = mean_vote_demo, colour = "Democrat"), 
              method = "lm", formula = y ~ poly(x, 3), se = FALSE) +
  geom_vline(xintercept = 40, 
             color = "black", linetype = "dashed", size = 0.6) +
  scale_colour_manual(values = c("Republican" = "#FF9999", "Democrat" = "#9999FF"),
                      name = "Party",  
                      labels = c("Democrat", "Republican")) +
  theme_minimal() +
  theme(legend.position = "none") + 
  labs(x = "DPC Rate Percentiles", 
       y = "Number of Votes")

pred <- predict(lm(mean_rep ~ poly(income_pctile, 3), data = binned_data2), 
                           newdata = binned_data2)

plot3 <- ggplot(binned_data2, aes(x = income_pctile)) +
  geom_point(aes(y = mean_rep, colour = "Republican"), alpha = 0.25) +  
  geom_smooth(aes(y = mean_rep, colour = "Republican"), 
              method = "lm", formula = y ~ poly(x, 3), se = FALSE) +
  geom_point(aes(y = mean_demo, colour = "Democrat"), alpha = 0.25) + 
  geom_smooth(aes(y = mean_demo, colour = "Democrat"), 
              method = "lm", formula = y ~ poly(x, 3), se = FALSE) +
  geom_vline(xintercept = which.max(pred), 
             color = "black", linetype = "dashed", size = 0.6) +
  scale_colour_manual(values = c("Republican" = "#FF9999", "Democrat" = "#9999FF"),
                      name = "Party",  
                      labels = c("Democrat", "Republican")) +
  theme_minimal() +
  theme(legend.position = "none") + 
  labs(x = "Income Percentiles", 
       y = "Votes Share (%)")

plot4 <- ggplot(binned_data2, aes(x = income_pctile)) +
  geom_point(aes(y = mean_vote_rep, colour = "Republican"), alpha = 0.25) +  
  geom_smooth(aes(y = mean_vote_rep, colour = "Republican"), 
              method = "lm", formula = y ~ poly(x, 3), se = FALSE) +
  geom_point(aes(y = mean_vote_demo, colour = "Democrat"), alpha = 0.25) + 
  geom_smooth(aes(y = mean_vote_demo, colour = "Democrat"), 
              method = "lm", formula = y ~ poly(x, 3), se = FALSE) +
  geom_vline(xintercept = 25, 
             color = "black", linetype = "dashed", size = 0.6) +
  geom_vline(xintercept = 78, 
             color = "black", linetype = "dashed", size = 0.6) +
  scale_colour_manual(values = c("Republican" = "#FF9999", "Democrat" = "#9999FF"),
                      name = "Party",  
                      labels = c("Democrat", "Republican")) +
  theme_minimal() +
  theme(legend.position = "none") + 
  labs(x = "Income Percentiles", 
       y = "Number of Votes")

library(cowplot)
legend <- get_legend(plot1 + theme(legend.position = "bottom"))
combined_plot <- plot_grid(plot1, plot2, plot3, plot4, ncol = 2)
combined_plot_with_legend <- plot_grid(combined_plot, legend, ncol = 1, rel_heights = c(1, 0.1))

print(combined_plot_with_legend)
```

Given the insights from @tbl-covid and @fig-map, @fig-dpc-income further examine the impact of COVID and income levels on the voting behaviors for the two parties. @fig-dpc-income shows the correlation between the votes of the two parties to the death per case rate and income levels. The two graphs on the left indicates the share of votes whereas the right two graphs indicate the number of votes. The two parties are represented by different colors. In terms of share of votes, in general, there is a positive relationship between the DPC and votes for the Democrat but a negative one for the Republican. However, the counties with medium value of DPC is less sensitive to the voting for the two parties, compared to the "tail" counties which their support change significantly as DPC increases or decreases. Meanwhile, there is a quadratic patterns between the vote for the two parties and income, it seems that the Republican is in favor of low income counties, but as income increase, more counties vote for Bide not Trump.

In addition, even though the average share of votes for Republican is always higher than 0.5, it does not necessarily mean that the Democrat lost in all counties. The reason behind this is, as mentioned in @tbl-covid, the counties which the Republican won is about five times as higher as the Democrat. Since Republican has more counties, it definitely has a higher average share of votes than Democrat. This pattern also indicate that Democrat usually won the densely populated, urban areas but Republican won in more sparsely populated, rural areas \[citation\]. The high population density areas has more votes and explains why Biden beat Trump. We can verify this from the number of votes for the two parties, where the number of votes for Biden exceeds Trump as DPC and income level increases. This pattern is especially significant for the top 50% richest counties and the counties with DPC larger than 75 quantile.

```{r}
data_population <- data %>% 
  mutate(pop_pctile = ntile(total_population, 100)) %>% 
  group_by(pop_pctile) %>% 
  summarise(county_demo = sum(winning_party == "Democrat")/n(),
            county_rep = sum(winning_party == "Republican")/n())

data_population %>% 
  ggplot(aes(x = pop_pctile)) +
  geom_point(aes(y = county_rep, colour = "Republican"), alpha = 0.25) +  
  geom_smooth(aes(y = county_rep, colour = "Republican"), 
              method = "lm", formula = y ~ poly(x, 3), se = FALSE) +
  geom_point(aes(y = county_demo, colour = "Democrat"), alpha = 0.25) + 
  geom_smooth(aes(y = county_demo, colour = "Democrat"), 
              method = "lm", formula = y ~ poly(x, 3), se = FALSE) +
  scale_colour_manual(values = c("Republican" = "#FF9999", "Democrat" = "#9999FF"),
                      name = "Party",  
                      labels = c("Democrat", "Republican")) +
  theme_minimal() +
  theme(legend.position = "bottom") + 
  labs(x = "Population Percentiles", 
       y = "Share of winning counties")
```

```{r}
boundaries <- c(0, 5000, 9000, 14000, 19000, 26000, 37000, 54000, 94000, 215000, Inf)

# Classify the counties into percentiles
data_population <- data %>% 
  mutate(pop_pctile = cut(total_population, breaks = boundaries, include.lowest = TRUE, labels = FALSE))

# data_population %>% 
#   filter(winning_party == "Republican") %>% 
#   ggplot(aes(x = pop_pctile)) +
#   geom_bar(aes(y = n()))
# 
# data_population %>% 
#   group_by(pop_pctile, winning_party) %>% 
#   summarise(n = n())
# 
# county_sum <- data_population %>%
#   filter(winning_party == "Republican") %>%
#   group_by(pop_pctile) %>%
#   summarize(count = n())

# Plot the data
# ggplot(county_sum, aes(x = pop_pctile, y = count)) +
#   geom_bar(stat = "identity")
```

From four graphs in @fig-dpc-income, we can conclude that, in general, the higher the DPC rate, the lower the support for Trump but higher for Biden. Besides, the Democrat is in favor of richer voters, where as Republican is in favor of low income counties. It is direct to ask whether these two variables have interaction effect on the voting patterns? However, it will be difficult to visualize the interaction effect between two continuous factors. Instead, I will manually set a new categorical variable `high_income` to denote whether the county has a high income with certain cutoff. Then the difference of correlations of the two groups as death per case rate changes. I will set different cutoffs to fully test the interaction effect.


```{r}
#| echo: false
#| message: false
#| label: fig-boxplot
#| fig-cap: Summary of income levels for counties voting for Democratic and Republican

data  %>%
  ggplot(mapping = aes(x = winning_party, y = mean_household_income)) +
  geom_boxplot() +
  geom_jitter(alpha = 0.04, width = 0.3, height = 0) +
  theme_minimal() +
  labs(x = "Winning Party",
       y = "Mean Household Income")
```

```{r, fig.width=10, fig.height=4.5}
#| echo: false
#| message: false
#| label: fig-income_state
#| fig-width: 10
#| fig-height: 4.5
#| fig-cap: Variation in COVID-19 Mortality Rates Across States, Categorized by Income Levels and Dominant Political Preferences

# Find the wining data for each state
data_win_party <- data %>%
  group_by(state) %>%
  summarise(dem_votes = sum(vote_demo),
            rep_votes = sum(vote_rep), 
            .groups = 'drop') %>% 
  mutate(winning_party_state = ifelse(dem_votes > rep_votes, 'Democratic', 'Republican')) %>% 
  dplyr::select(state, winning_party_state)
# Calculate the average income
average_income_by_state <- data %>%
  group_by(state) %>%
  summarise(average_income = mean(mean_household_income), .groups = 'drop')
# Join the winning party and average income back to the original data
data_win_party_income <- data %>%
  left_join(data_win_party, by = "state") %>%
  left_join(average_income_by_state, by = "state")
# Arrange states by average income
ordered_states <- data_win_party_income %>%
  arrange(average_income) %>%
  .$state %>%
  unique()
# Create a factor with levels based on income-ordered states for plotting
data_win_party_income$state <- factor(data_win_party_income$state, levels = ordered_states)

average_dpc <- mean(data_win_party_income$mortrate)

ggplot(data_win_party_income, aes(x = state, y = mortrate, fill = winning_party_state)) +
  geom_boxplot() +
  geom_hline(yintercept = average_dpc, linetype = "dashed", color = "black") +
  annotate("text", x = Inf, y = average_dpc, label = " National Average", hjust = 1, vjust = -0.5, color = "black", size = 3) +
  scale_fill_manual(values = c('Democratic' = 'blue', 'Republican' = 'red')) +
  labs(y = 'Death Rate', x = 'State (Ascending Income)', 
       fill = "Winning Party") +
  theme_minimal() +
  theme(legend.position = "bottom") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

@fig-boxplot compares the distribution of county income levels for the two parties. In general, counties voting for the Democrats have higher income levels than the Republicans. In addition, we can observe that the counties are intensively concentrated around income levels \$50k to \$75k, compared to the Democrats, where the counties are approximately uniformly distributed at each income level. Furthermore, barely any county has at least 150k voting for the Republican party. Both @tbl-covid and @fig-boxplot indicates that the Democrat is in favour of wealthy counties but poorer counties for Republican. Consequently, the more affluent counties (states) usually have more electoral votes than the poorer ones; this may provide insights into why Trump lost.

# Methods

The objective in this paper is to conduct the causal inference between COVID-19 and Trump's loss during 2020, the main methods implemented in this study will be the Propensity Score Matching (PSM). After find the causal inference, this paper will also conduct a counterfactual analysis to see whether Trump can re-elect if there was no COVID.

## Treatment

The treatment refers to the intervention or exposure that is being studied to understand its potential impact on the outcome. In other words, we implement certain interventions to a group of people but not for the rest. The group of people receiving the treatment is called the treatment group and control group for the rest. For instance, Jochen \[citation\] examined whether a new medical treatment called clampless off-pump coronary artery bypass (clampless OPCAB) will reduce the in-hospital mortality rate, compared to the traditional way. In their studies, the treatment is the new medical surgery and patients who took this surgery is the treatment group. They compared the mortality rates between the two groups and concluded that the new treatment can significantly lower the stroke and mortality rate.

Normally, the treatment should be established before conduct the analysis, this aims to reduce the risk of p-hacking. However, the objective of this paper is to find whether Trump lost the last Election due to COVID-19, it may not be possible to state the treatment in advance as all the counties in US had experienced COVI-19. Therefore this paper will firstly perform exploratory analysis to firstly find the treatment group which has the most significant difference in voting for Trump. This paper will set a cutoff defining whether a county has a high or low death per case rate. In addition, from @fig-dpc-income, low and high income counties also seem to have different voting behaviors. Therefore the treatment in this paper will incorporate whether a county has a high DPC and a high income levels with certain cutoffs. 

However, we need to be very careful about the cutoffs for defining "high" in DPC and income is crucial as the risk of p-hacking or data dreging may raise. P-hacking means the manipulation of data analysis until we can find the statistically significant results [citation]. If we simply choose one cutoff and find the significant results that match the common sense, it may raise the p-hacking risk and the analyses will be less convincing. Therefore, to make the analysis more comprehensive, instead of choosing a single cutoff, I will set a grid of cutoffs for each variable to see how the separate or combine treatment effects varies. For example, one treatment groups can be counties with death per case and income levels higher than 0.3 quantiles. By this way, we should be able to find the optimal treatment group and avoid the risk of p-hacking.

## Propensity Score Matching (PSM)

To estimate the treatment effects, randomized controlled trials (RCT) is the most ideal and the golden way to do this \[citation\]. The reason is that RCTs is the only way that guarantees the equal distribution of known and unknown parameters. Therefore the outcomes between the treatment and control groups will not be confounded. However, conducting a RCT is nearly impractical and impossible. Back to the coronary artery bypass example \[citation\], you can not force a patient to take new or traditional treatment, the researchers can not control it and hence RCT is impossible. Instead, we can take observational studies to find the treatment effects.

One method that can be applied to observational studies to find the treatment effect is Propensity Score Matching (PSM). Propensity score is the probability of an observation that receive the treatment based on the existing covariates using logistic regression. Using propensity scores have one main advantages which is dimension reduction [citation]. Dimension reduction means we can describe an observation by only its propensity score instead of a list of covariates. Therefore, we can match two observations having similar propensity scores but from treatment and control groups separately. With this algorithm, we can have many matched pairs and the matching process is called propensity score matching. Here, we have another advantage of PSM which is design separation [citation], meaning that it can separate the covariates balancing and effects estimation. I will show the balance of covariates later. Finally, we can directly estimate their outcomes and solve the drawback that we can not have causal inference from observational studies. That is why it can also separate designs and this process is called propensity score matching.

In this paper, the propensity scores are used to estimate how likely a county having a high DPC or high income levels (or both) using multiple linear logistic regression. The model will be look like:

```{=tex}
\begin{align*}
\log\left(\frac{P(T=1|X)}{1 - P(T=1|X)}\right) = \beta_0 + \beta_1 X_1 +\cdots +\beta_p X_p
\end{align*}
```
where:\
* $P(T=1|X)$ is the probability of a county receiving treatment\
* $X_j\:(1\leq j\leq p)$ are the covariates\
* $\beta_0$ is the intercept
* $\beta_j\:(1\leq j\leq p)$ is the corresponding coefficients of each covariate\

Using the model, I will calculate the propensity scores for each county and match the data with similar propensity scores. Notice that the values of propensity scores changes as the treatment changes. That said, I will calculate the propensity scores and match the data for number of treatment times.

## Counterfactual Analysis

Using the PSM described previously, we can find the treatment effects under different settings of treatment groups. However, to conclude whether Trump was lost due to COVID, we need to perform a counterfactual analysis with re-calculating the votes for Trump of counties in the treatment group.

The couterfactual analysis is particularly necessary for those "swing" states in 2020. In 2016 Federal Election, one key factory why Trump defeated Hillary is that he won seven out of eleven swing states. However, he only won three of them in 2020 [citaion (wikipedia)]. Besides, if Donald Trump were able to hold onto three swing states which are Georgia, Arizona and Wisconsin where the average margin of Democrat is only about 0.3%, the result would have been a 269-269 electoral tie decided in the House of Representatives [citation (wikipedia)]. Then the presidential election is left up to members of the House of Representatives and it is possible that Trump can win.

To find the voting patterns for Trump, especially for the "swing" states, I will follow the official election procedure and use the winners-takes-all rule. That said, I will re-calculate the votes for Trump in county level and summarize by county level. Then the party with higher total votes will take all the electoral votes in this state. Eventually, I will calculate the total electoral votes for each party to see whether Trump could re-elect if the treatment effects diminish. Besides, I will also predict the votes if the death number can reduce 5%, 10%..., to see if a tiny decrease in deaths will make Trump to re-elect.

# Results

## Choise of treatment groups

```{r}
#| fig-width: 8
#| fig-height: 5
#| fig-cap: 'The Correlation Between Voting for Trump and Income Levels, Categorized by DPC Rate at Varied Quantile Cutoffs (e.g., Top 40% as High-DPC and bottom 60% as Low-DPC for "Cutoff: 0.6")'
#| label: fig-dpc
#| message: false
#| warning: false

generate_plot2 <- function(cutoff, y_var, colours, y_limits) {
  data_processed <- data %>%
    mutate(income_pctile = ntile(mean_household_income, 20),
           high_dpc = as.factor(ifelse(dpc > quantile(dpc, cutoff), 1, 0))) %>%
    group_by(income_pctile, high_dpc) %>%
    summarise(y_value = mean({{ y_var }}), .groups = "drop")  # Use dynamic variable
  
  ggplot(data_processed, aes(x = income_pctile, y = y_value, color = high_dpc)) +
    geom_point(alpha = 0.25) +
    geom_smooth(method = "lm", formula = y ~ poly(x, 2), se = FALSE) +
    theme_minimal() +
    scale_color_manual(values = c("1" = colours[1], "0" = colours[2]),
                       name = "DPC Level",
                       labels = c("0" = "Low DPC", "1" = "High DPC")) +
    ylim(y_limits[1], y_limits[2]) +
    theme(legend.position = "none",
          axis.title.x = element_blank(),
          axis.title.y = element_blank(),
          plot.title = element_text(size = 10)) + 
    labs(x = "Income Percentile", y = deparse(substitute(y_var)),
         title = paste("Cutoff:", cutoff))
}


cutoffs <- seq(0.1, 0.9, by = 0.1)

# Assuming 'pct_vote_rep' is a column in your 'data' dataframe
plots <- lapply(cutoffs, function(cutoff) generate_plot2(cutoff, 
                                                        y_var = pct_vote_rep,
                                                        c("#FF6347", "#FFB6C1"),
                                                        c(0.4, 0.8)))


library(cowplot)
legend <- get_legend(plots[[1]] + theme(legend.position = "bottom",  # Place legend at the bottom
        legend.justification = "center",  # Justify legend in the center
        legend.box.just = "bottom"))
combined_plot <- plot_grid(plotlist = plots[1:9], ncol = 3)
combined_plot_with_legend <- plot_grid(combined_plot, legend, ncol = 1, rel_heights = c(1, 0.1))
ggdraw() +
  draw_plot(combined_plot_with_legend) +
  draw_label("Income Rate Percentiles", x = 0.5, y = 0, hjust = 0.5, size = 12) +
  draw_label("Share of Vote for Republican", x = -0.03, y = 0.5, angle = 90, vjust = 0.5, size = 12) +
  theme(plot.margin = margin(t = 10, r = 10, 
                             b = 10, l = 40, unit = "pt"))
```

@fig-dpc shows the correlation between votes for Trump and income levels, segmented into "High-DPC" and "Low-DPC" county groups at varying DPC cutoffs. For instance, a cutoff of 0.3 classifies counties with a DPC rate below this threshold as "Low DPC," and those above as "High DPC.". By comparing these groups across different cutoffs, we aim to identify the cutoff where the difference in voting for Trump across difference income levels is most pronounced. With that said, we can find that except cutoff 0.4, the two line converge as income increases (right tail). Only for the 0.4 cutoff, the lines of two groups converge at the middle-income but do not overlap and diverge at the tails. Additionally, regardless of the cutoff applied, there is a common pattern that the support for Trump increases in poorer counties up to around the eighth bin, which is approximately the 0.4 income quantile, and then decreases in wealthier counties. This indicates a significant voting disparity between counties below and above the 0.4 income quantile.

```{r}
#| fig-width: 8
#| fig-height: 5
#| fig-cap: 'The Correlation Between Voting for Trump and DPC Rate, Categorized by Income Levels at Varied Quantile Cutoffs (e.g., Top 40% as High Income and bottom 60% as Low Income for "Cutoff: 0.6")'
#| label: fig-income
#| message: false
#| warning: false

generate_plot <- function(cutoff, y_var, colours, y_limits) {
  data_processed <- data %>%
    mutate(dpc_pctile = ntile(dpc, 20),
           high_income = as.factor(ifelse(mean_household_income > quantile(mean_household_income, cutoff), 1, 0))) %>%
    group_by(dpc_pctile, high_income) %>%
    summarise(y_value = mean({{ y_var }}), .groups = "drop")  # Use dynamic variable
  
  ggplot(data_processed, aes(x = dpc_pctile, y = y_value, color = high_income)) +
    geom_point(alpha = 0.25) +
    geom_smooth(method = "lm", formula = y ~ poly(x, 2), se = FALSE) +
    theme_minimal() +
    scale_color_manual(values = c("1" = colours[1], "0" = colours[2]),
                       name = "Income Level",
                       labels = c("0" = "Low Income", "1" = "High Income")) +
    ylim(y_limits[1], y_limits[2]) +
    theme(legend.position = "none",
          axis.title.x = element_blank(),
          axis.title.y = element_blank(),
          plot.title = element_text(size = 11)) + 
    labs(x = "DPC Percentile", y = deparse(substitute(y_var)),
         title = paste("Cutoff:", cutoff))
}


cutoffs <- seq(0.1, 0.9, by = 0.1)

# Assuming 'pct_vote_rep' is a column in your 'data' dataframe
plots <- lapply(cutoffs, function(cutoff) generate_plot(cutoff, 
                                                        y_var = pct_vote_rep,
                                                        c("#FF6347", "#FFB6C1"),
                                                        c(0.4, 0.8)))


library(cowplot)
legend <- get_legend(plots[[1]] + theme(legend.position = "bottom",  # Place legend at the bottom
        legend.justification = "center",  # Justify legend in the center
        legend.box.just = "bottom"))
combined_plot <- plot_grid(plotlist = plots[1:9], ncol = 3)
combined_plot_with_legend <- plot_grid(combined_plot, legend, ncol = 1, rel_heights = c(1, 0.1))
ggdraw() +
  draw_plot(combined_plot_with_legend) +
  draw_label("DPC Rate Percentiles", x = 0.5, y = 0, hjust = 0.5, size = 12) +
  draw_label("Share of Vote for Republican", x = -0.03, y = 0.5, angle = 90, vjust = 0.5, size = 12) +
  theme(plot.margin = margin(t = 10, r = 10, 
                             b = 10, l = 40, unit = "pt"))
```

Furthering on our analysis, @fig-income shows the correlation between Trump's vote share and the DPC rate but this time dividing counties based on income levels into "High Income" and "Low Income" groups. Each subplot in this analysis corresponds to a different income cutoff. Compared to @fig-dpc, all curves, regardless of the cutoff, display a linear or near-linear relationship with voting patterns. As the income cutoff increases, the difference in voting behavior between the high and low-income counties becomes more distinct, especially at the 0.9 cutoff. This suggests that in counties with higher incomes, voting patterns vary significantly from those in lower-income counties as the DPC rate changes. Therefore, the most significant pattern is observed at the 0.9 income cutoff, contradicted to the patterns identified in @fig-dpc.

So, should we include all the income levels and DPC in the settings of treatment? The answer is NO and we should only include the DPC. From @fig-dpc, a consistent quadratic relationship between income and voting patterns for Trump is evident, regardless of how the cutoff for defining high DPC is adjusted. This pattern demonstrates that poorer counties (in the first half of the income spectrum) may show a positive or a positive correlation with voting for Trump depending on the cutoff we choose, whereas richer counties will only exhibit a negative correlation. This quadratic pattern can be verifies from @fig-dpc-income, which illustrates a similar relationship between votes and income. Conversely, @fig-income presents a different narrative. Here, all regression lines, irrespective of the DPC cutoff, display a linear or nearly linear relationship. Besides, unlike the @fig-dpc, all the lines in @fig-income shows a negative slope, meaning that the choice of cutoff for "High DPC" group will not change the general voting patterns for Trump. The optimal cutoff we found previously, 0.4, is the one that the "High DPC" and "Low DPC" have the maximum difference. This finding can be also verified from @fig-dpc-income, which shows a monotonically decreasing cubic correlation between votes and DPC. The @fig-treatment shows a simple visualization of why is the case.

```{r}
#| fig-width: 8
#| fig-height: 3
#| label: fig-treatment
# Splitting the data into two subsets
left_data <- subset(binned_data, dpc_pctile <= 65)
right_data <- subset(binned_data, dpc_pctile > 65)

# Creating new subsets for the x-intercept at 40
left_data_40 <- subset(binned_data, dpc_pctile <= 40)
right_data_40 <- subset(binned_data, dpc_pctile > 40)

# Base plot with cubic regression and vertical lines
p1 <- ggplot(binned_data, aes(x = dpc_pctile)) +
  geom_smooth(aes(y = mean_rep), colour = "black", method = "lm", 
              formula = y ~ poly(x, 3), se = FALSE, size = 1) +
  geom_vline(xintercept = 65, color = "lightgrey", linetype = "dashed", size = 0.8) +
  geom_vline(xintercept = 40, color = "#E69F00", linetype = "dashed", size = 0.8) +
  geom_smooth(data = left_data, aes(y = mean_rep, colour = "65"), 
                     method = "lm", formula = y ~ x, se = FALSE, linetype = "dashed", size = 0.8) +
  geom_smooth(data = right_data, aes(y = mean_rep, colour = "65"), 
                     method = "lm", formula = y ~ x, se = FALSE, linetype = "dashed", size = 0.8) + 
  geom_smooth(data = left_data_40, aes(y = mean_rep, colour = "40"), 
                method = "lm", formula = y ~ x, se = FALSE, linetype = "longdash", size = 0.8) +
  geom_smooth(data = right_data_40, aes(y = mean_rep, colour = "40"), 
                method = "lm", formula = y ~ x, se = FALSE, linetype = "longdash", size = 0.8) +
  theme_minimal() +
  scale_color_manual(values = c("65" = "lightgrey", "40" = "#E69F00"),
                       name = "Cutoffs",
                       labels = c("65" = "0.65 Quantile", "40" = "0.4 Quantile")) +
  theme(legend.position = "bottom",
          axis.title.y = element_blank()) +
  labs(x = "DPC Rate Percentiles", y = "Votes Share (%)")


# Splitting the data into two subsets
left_data <- subset(binned_data2, income_pctile <= 90)
right_data <- subset(binned_data2, income_pctile > 90)

# Creating new subsets for the x-intercept at 40
left_data_40 <- subset(binned_data2, income_pctile <= 40)
right_data_40 <- subset(binned_data2, income_pctile > 40)

p2 <- ggplot(binned_data2, aes(x = income_pctile)) +
  geom_smooth(aes(y = mean_rep), colour = "black", 
              method = "lm", formula = y ~ poly(x, 3), se = FALSE, size = 1) +
  geom_vline(xintercept = 90, color = "lightgrey", linetype = "dashed", size = 0.8) +
  geom_vline(xintercept = 40, color = "#E69F00", linetype = "dashed", size = 0.8) +
  geom_smooth(data = left_data, aes(y = mean_rep, colour = "90"), 
                     method = "lm", formula = y ~ x, se = FALSE, linetype = "dashed", size = 0.8) +
  geom_smooth(data = right_data, aes(y = mean_rep, colour = "90"), 
                     method = "lm", formula = y ~ x, se = FALSE, linetype = "dashed", size = 0.8) + 
  geom_smooth(data = left_data_40, aes(y = mean_rep, colour = "40"), 
                method = "lm", formula = y ~ x, se = FALSE, linetype = "longdash", size = 0.8) +
  geom_smooth(data = right_data_40, aes(y = mean_rep, colour = "40"), 
                method = "lm", formula = y ~ x, se = FALSE, linetype = "longdash", size = 0.8) +
  theme_minimal() +
  scale_color_manual(values = c("90" = "lightgrey", "40" = "#E69F00"),
                       name = "Cutoffs",
                       labels = c("90" = "0.90 Quantile", "40" = "0.4 Quantile")) +
  theme(legend.position = "bottom",
          axis.title.y = element_blank()) +
  labs(x = "Income Percentiles", y = "Votes Share (%)")


library(cowplot)

combined_plot <- plot_grid(p1, p2, nrow = 1)
ggdraw() +
  draw_plot(combined_plot) +
  draw_label("Share of Vote for Republican", x = -0.03, y = 0.5, angle = 90, vjust = 0.5, size = 12) +
  theme(plot.margin = margin(t = 10, r = 10, 
                             b = 10, l = 40, unit = "pt"))
```

@fig-treatment shows a simple example when we test different cutoffs for DPC rate and income. From the graph, we can see that no matter which cutoff we set, the low DPC and high DPC counties always have the a negative value of slope. The only difference is the absolute values of the slope. However, for the income, we can see that for the cutoff 0.4 quantile, the low income and high income groups show a opposite patterns for voting for Trump. But when we increase the cutoff to 0.9 quantile. The two groups are both negatively related to the change. This indicates that it is not appropriate to incorporate income in treatment as the choice of cutoff will significant change the 

no matter which cutoff we set, the two groups will always have opposite altitude for voting for Trump. Suppose we have enough samples, when we include income into the treatment, then treatment effect will always be more negative when we increase the cutoff. The treatment effect will be more and more significant when we increase the cutoff. However, the number of counties in treatment group will decrease and hence it will be unnecessary to have income into treatment settings.

From @fig-dpc, we already verify that cutoff 0.4 is the optimal threshold for defining high and low DPC group, therefore the treatment group will be the counties having DPC rate larger than 0.4 quantile. Furthermore, to balance the effect of income, I will incorporate income into the ways to calculate the propensity scores for each county.

## Propensity Score Matching

In my previous paper, I already show that proportion of residence with at least a bachelor degree, income, proportion of people with private insurance and withou health insurance, ratio of males, ratio of black and black residence are statistically in predicting the probability of a county has a high mortality rate or not. In this paper, I will directly use the results and only consider these variables when predicting the propensity scores.

```{=tex}
\begin{align*}
\log\left(\frac{P(T=1|X)}{1 - P(T=1|X)}\right) &= 8.06 \\
& -0.02 \times \text{prop\_higher\_education} \\
& +0.01 \times \text{pctile} \\
& +0.01 \times \text{no\_insurance} \\
& -0.03 \times \text{private\_insurance} \\
& -0.13 \times \text{males} \\
& +0.00 \times \text{white\_pct} \\
& +0.06 \times \text{black\_pct}
\end{align*}
```

The above equation shows the logistic regression model to predict the propensity score for each county. It seems that males is the most critical factor when predict the propensity score. Perhaps the majority of COVID deaths are males. Interestingly, the counties with a higher income levels will have a higher death per case rate. This may explain why richer counties are less likely to vote for Trump.

```{r}
#| echo: false
#| warning: false
#| message: false
#| tbl-cap: The summary of Propensity Score Matching
#| label: tbl-psm

library(dplyr)
data <- read.csv(here("outputs/data/merged_data.csv"))

data_te <- data %>% 
  mutate(high_dpc = ifelse(dpc > quantile(dpc, 0.4), 1, 0),
         high_income = ifelse(mean_household_income > quantile(mean_household_income, 0.9), 1, 0),
         treatment = high_dpc)
highinf_model <- glm(treatment ~ prop_higher_education  + pctile +
                       no_insurance + private_insurance + males +
                       white_pct + black_pct, family = binomial(),
                      data = data_te)
data_te$prop_score <- predict(highinf_model, type = "response")

library(Matching)
library(kableExtra)
# Propensity score matching
rr <- Match(Y = data_te$pct_vote_rep, Tr = data_te$treatment,
            X = data_te$prop_score, M = 1)

data.frame(estimate = -0.018342,
           p = 0.021404,
           on = 3115,
           ot = 1869,
           mo=1869,
           mou = 5415) %>% 
  rename(`Treatment Effect` = estimate,
         `P value` = p,
         `Obs.` = on,
         `Treat. Obs.` = ot,
         `Treat. Obs` = mo,
         `Treat. Obs. Unw.` = mou) %>% 
  kable(booktabs = TRUE) %>% 
  add_header_above(c(" " = 2,
                     "Original" = 2, "Matched" = 2))
```

@tbl-psm summarize the results of Propensity Score Matching. The treatment effect is about -0.18 means that the counties with DPC rate higher than 0.4 will in average vote 0.018 less for Trump, compared to the counties with lower DPC rate. This value is statistically significant as its p value is about 0.02 which is lower than 0.05. In addition, there are 1869 treatment observations in both original and matched data, meaning that there some counties in control group that are matched more than once.

```{r}
#| label: tbl-balance
#| tbl-cap: The balance of each covariates before and after the mathcing
# Load necessary libraries
library(knitr)
library(kableExtra)

# Prepare your data
data.frame(
  var = c("prop_higher_education", "pctile", "no_insurance", "private_insurance", "males", "white_pct", "black_pct"),
  before_mean_control = c(23.246, 51.774, 8.7107, 67.656, 50.512, 87.137, 4.1685),
  before_std_mean_diff = c(-10.772, -10.389, 24.449, -35.913, -32.492, -47.207, 49.083),
  after_mean_control = c(21.633, 47.804, 9.7494, 63.409, 49.552, 79.636, 11.456),
  after_std_mean_diff = c(5.6159, 2.9221, 4.6766, 5.955, 9.6593, -5.5169, 5.4646)
) %>% 
  rename(`Variables` = var,
         `Mean Contr` = before_mean_control,
         `Std Mean Diff` = before_std_mean_diff,
         `Mean Contr.` = after_mean_control,
         `Std Mean Diff.` = after_std_mean_diff) %>% 
  kable(booktabs = TRUE) %>%
  kable_styling(full_width = FALSE) %>%
  add_header_above(c(" " = 1, "Before Matching" = 2, "After Matching" = 2))
```

@tbl-balance summarize each variable's mean values in the control group and standard mean difference before and after the matching. We can see that the mean values in the control group approximately remain same after the matching. Besides, there is a significant decrease in the standard mean difference for each variable. This indicates that the Propensity Score Matching reduced the imbalance between the treatment and control group considerablely.

## Counterfactual Analysis

```{r}
#| tbl-cap: The summary of counterfactual votes for the eleven swing staes in 2020
#| label: tbl-counter
electoral_votes_state <- read.csv(here("outputs/data/electoral_votes_state.csv"))
swing_states_2020 <- c("FL", "PA", "MI", "WI", "AZ", "NC", "GA", "IA", "NV", "MN", "NH")

data_new <- data_te %>%
  mutate(vote_rep = ifelse(treatment == 1, total_votes*(pct_vote_rep + 0.018342), vote_rep),
         vote_demo = ifelse(treatment == 1, total_votes*(pct_vote_demo - 0.018342), vote_demo))

data_c <- data_new %>%
  filter(state %in% swing_states_2020) %>% 
  group_by(state) %>% 
  summarise(total_votes_rep_counter = sum(vote_rep),
            total_votes_demo_counter = sum(vote_demo))

data_counter <- data %>% 
  filter(state %in% swing_states_2020) %>% 
  group_by(state) %>% 
  summarise(total_votes_rep_real = sum(vote_rep),
            total_votes_demo_real = sum(vote_demo)) %>% 
  left_join(data_c, by = "state") %>% 
  mutate(margin_real = ifelse(total_votes_rep_real > total_votes_demo_real, 
                         paste0(round(100 * (total_votes_rep_real - total_votes_demo_real) / (total_votes_rep_real + total_votes_demo_real), 2), "% R"),
                         ifelse(total_votes_rep_real < total_votes_demo_real, 
                                paste0(round(100 * (total_votes_demo_real - total_votes_rep_real) / (total_votes_rep_real + total_votes_demo_real), 2), "% D"),
                                "Equal")),
         margin_counter = ifelse(total_votes_rep_counter > total_votes_demo_counter, 
                         paste0(round(100 * (total_votes_rep_counter - total_votes_demo_counter) / (total_votes_rep_counter + total_votes_demo_counter), 2), "% R"),
                         ifelse(total_votes_rep_counter < total_votes_demo_counter, 
                                paste0(round(100 * (total_votes_demo_counter - total_votes_rep_counter) / (total_votes_rep_counter + total_votes_demo_counter), 2), "% D"),
                                "Equal"))) %>% 
  arrange(desc(total_votes_demo_real/(total_votes_rep_real + total_votes_demo_real))) %>% 
  left_join(electoral_votes_state, by = "state") %>% 
  dplyr::select(state, electoral_votes, total_votes_rep_real, 
                total_votes_demo_real, margin_real, total_votes_rep_counter, 
                total_votes_demo_counter, margin_counter)

data_counter %>% 
  rename(`States` = state,
         `Electoral Votes` = electoral_votes,
         `Trump` = total_votes_rep_real,
         `Biden` = total_votes_demo_real,
         `Margin` = margin_real,
         `Trump*` = total_votes_rep_counter,
         `Biden*` = total_votes_demo_counter,
         `Margin*` = margin_counter) %>% 
  kable(booktabs = TRUE) %>% 
  add_header_above(c(" " = 2, "Actual Results" = 3, "Simulated Results*" = 3))
```

@tbl-counter shows the summary of vote for the eleven swing states in 2020 if the difference in voting for Trump between the high DPC and low DPC eliminates. This equivalent to on average In 2020, the truth is that the Trump only won three of eleven swing states and he only won 232 electoral votes. However, with counterfactual votes, Trump will win five more states and hence bring him 52 more electoral votes. Therefore the total electoral votes for Trump will be 284. Since the cutoff to win is 270 votes, this indicate that Trump could re-elect if he can eliminate the disparities in DPC rate.


# Discussion

## First discussion point {#sec-first-point}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this.

## Second discussion point

## Third discussion point

## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

# References
